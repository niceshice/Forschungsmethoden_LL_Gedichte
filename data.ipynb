{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\vinze\\Desktop\\Uni\\DH\\Forschun gsmethoden\\corpus_finished'  # Replace with your actual directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender m:\n",
      "Unique titles: 135\n",
      "Unique authors: 58\n",
      "Total tokens: 21113\n",
      "Category counts:\n",
      "Leben & Beziehungen: 74\n",
      "Natur: 65\n",
      "Tiere: 18\n",
      "Pflanzen: 17\n",
      "Reimgedicht: 15\n",
      "Landschaft: 13\n",
      "Zeit: 9\n",
      "Erinnerung: 8\n",
      "Wasser: 8\n",
      "Tod / Trauer: 7\n",
      "Gesellschaft: 7\n",
      "Humoristische Poesie: 6\n",
      "Heimat: 6\n",
      "Essen & Trinken: 6\n",
      "Religion / SpiritualitÃ¤t: 6\n",
      "Familie: 6\n",
      "Liebe: 5\n",
      "Dichtung: 5\n",
      "Sprache: 5\n",
      "Serien / Zyklen: 5\n",
      "KÃ¶rper: 5\n",
      "Schreiben (Gedichte): 5\n",
      "IdentitÃ¤t (Individuum): 4\n",
      "Gesellschaftskritik: 4\n",
      "Lyrik fÃ¼r Kinder: 4\n",
      "Sommer: 4\n",
      "Stadt & stÃ¤dtisches Leben: 4\n",
      "Medizin & Naturwissenschaft: 4\n",
      "Photographie & Film: 3\n",
      "Popkultur: 3\n",
      "Alkohol & Drogen: 3\n",
      "Arbeit: 3\n",
      "Vater: 3\n",
      "Winter: 3\n",
      "Kultur & Wissenschaften: 3\n",
      "Spoken Word / Rap: 3\n",
      "Experimentelle Poesie: 3\n",
      "Ehe: 2\n",
      "Verlust & Trennung: 2\n",
      "Philosophie: 2\n",
      "Musik: 2\n",
      "Reisen: 2\n",
      "Kindheit & Jugend: 2\n",
      "Theater & Tanz: 2\n",
      "IdentitÃ¤t (kollektiv): 2\n",
      "FrÃ¼hling: 2\n",
      "Gestischer Rhythmus (= Betonte Enjambements): 2\n",
      "Politische Lyrik: 2\n",
      "Krieg: 2\n",
      "Wirtschaft: 2\n",
      "Architektur & Design: 2\n",
      "Mutter: 2\n",
      "Synkopen: 2\n",
      "Geschichte: 2\n",
      "Frau: 2\n",
      "Mann: 2\n",
      "Sonett: 2\n",
      "mit Musik / Sound: 1\n",
      "Ballade: 1\n",
      "Literatur & Lesen: 1\n",
      "Traditionen: 1\n",
      "Kind: 1\n",
      "Cut-up-Rhythmen: 1\n",
      "Lautpoesie: 1\n",
      "Konkrete Poesie: 1\n",
      "Herbst: 1\n",
      "Sex / Erotik: 1\n",
      "Beziehungskonflikt: 1\n",
      "Erotische Poesie: 1\n",
      "Ecopoetry / Nature writing: 1\n",
      "Gender & SexualitÃ¤t: 1\n",
      "Poetologische Gedichte: 1\n",
      "Kadenz: 1\n",
      "Exil: 1\n",
      "Mundart: 1\n",
      "Parlando: 1\n",
      "Alter: 1\n",
      "Politik: 1\n",
      "Variabler VersfuÃŸ: 1\n",
      "\n",
      "Gender w:\n",
      "Unique titles: 96\n",
      "Unique authors: 37\n",
      "Total tokens: 12329\n",
      "Category counts:\n",
      "Natur: 53\n",
      "Leben & Beziehungen: 46\n",
      "Tiere: 17\n",
      "Pflanzen: 15\n",
      "Landschaft: 14\n",
      "Serien / Zyklen: 10\n",
      "IdentitÃ¤t (Individuum): 8\n",
      "Tod / Trauer: 8\n",
      "Zeit: 8\n",
      "Musik: 7\n",
      "Erinnerung: 7\n",
      "Wasser: 7\n",
      "Reimgedicht: 6\n",
      "Liebe: 6\n",
      "Verlust & Trennung: 6\n",
      "Reisen: 5\n",
      "Lyrik fÃ¼r Kinder: 5\n",
      "KÃ¶rper: 5\n",
      "Mythologie: 4\n",
      "Stadt & stÃ¤dtisches Leben: 4\n",
      "Gender & SexualitÃ¤t: 4\n",
      "Beziehungskonflikt: 4\n",
      "Traum: 4\n",
      "Kunst & Malerei: 4\n",
      "Gesellschaftskritik: 3\n",
      "Winter: 3\n",
      "Narrative Poesie: 3\n",
      "Herbst: 3\n",
      "Familie: 3\n",
      "Kind: 3\n",
      "Sommer: 3\n",
      "Sprache: 2\n",
      "Mutter: 2\n",
      "Sex / Erotik: 2\n",
      "Alter: 2\n",
      "Essen & Trinken: 2\n",
      "Poetologische Gedichte: 1\n",
      "Schreiben (Gedichte): 1\n",
      "Heimat: 1\n",
      "Parlando: 1\n",
      "Gesellschaft: 1\n",
      "Gestischer Rhythmus (= Betonte Enjambements): 1\n",
      "Theater & Tanz: 1\n",
      "Photographie & Film: 1\n",
      "Kindheit & Jugend: 1\n",
      "Beerdigung: 1\n",
      "Spoken Word / Rap: 1\n",
      "Freundschaft: 1\n",
      "Alkohol & Drogen: 1\n",
      "Popkultur: 1\n",
      "Kultur & Wissenschaften: 1\n",
      "Arbeit: 1\n",
      "Medizin & Naturwissenschaft: 1\n",
      "Geschichte: 1\n",
      "Politik: 1\n",
      "Geburt: 1\n",
      "\n",
      "Number of files that failed to process: 0\n"
     ]
    }
   ],
   "source": [
    "# Prüft die FIles auf Verwendbarkeit; Erstellt DF; Zählt Autoren, Titel, KAtegorien und Tokens für die jeweiligen Gender\n",
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "df_list = []\n",
    "category_counts = defaultdict(lambda: defaultdict(int))  # Stores the counts of categories for each gender\n",
    "failed_files = 0\n",
    "\n",
    "for filename in all_files:\n",
    "    try:\n",
    "        with open(os.path.join(data_dir, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Only process the file if it contains the 'categories' field\n",
    "            if 'categories' in data:\n",
    "                # Flatten the poem dictionary into a DataFrame\n",
    "                poem_df = pd.DataFrame(data['poem']).T\n",
    "\n",
    "                # Repeat the other columns for each line of the poem\n",
    "                for column in ['title', 'gender', 'author']:\n",
    "                    poem_df[column] = data[column]\n",
    "\n",
    "                # Count each category for the corresponding gender\n",
    "                for category in data['categories']:\n",
    "                    category_counts[data['gender']][category] += 1\n",
    "\n",
    "                df_list.append(poem_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {filename}: {e}\")\n",
    "        failed_files += 1\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Function to calculate and print statistics\n",
    "def print_stats(df, gender):\n",
    "    gender_df = df[df['gender'] == gender]\n",
    "\n",
    "    unique_titles = gender_df['title'].nunique()\n",
    "    unique_authors = gender_df['author'].nunique()\n",
    "    total_tokens = gender_df['text'].apply(lambda x: len(x.split())).sum()\n",
    "\n",
    "    print(f\"Gender {gender}:\")\n",
    "    print(f\"Unique titles: {unique_titles}\")\n",
    "    print(f\"Unique authors: {unique_authors}\")\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "    # Print category counts\n",
    "    print(\"Category counts:\")\n",
    "    category_dict = dict(category_counts[gender])\n",
    "    sorted_categories = sorted(category_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    for category, count in sorted_categories:\n",
    "        print(f\"{category}: {count}\")\n",
    "    print(\"\")\n",
    "\n",
    "print_stats(df, 'm')\n",
    "print_stats(df, 'w')\n",
    "\n",
    "print(f\"Number of files that failed to process: {failed_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '125-episoden-imonki-16200.json', 'gender': 'm', 'categories': ['Leben & Beziehungen', 'Ehe', 'Verlust & Trennung', 'Tod / Trauer', 'Philosophie', 'Photographie & Film'], 'token_count': 537, 'word_frequency': {'125': 1, 'Episoden': 1, 'Monk': 1, '.': 1, 'In': 2, 'Worten:': 1, 'einhundertfnfundzwanzig': 1, 'Episoden,': 1, 'Monk!': 1, 'Stell': 1, 'dir': 1, 'vor,': 1, 'wie': 11, 'oft': 2, 'du': 6, 'mich': 2, 'begleitet': 1, 'hast': 1, 'in': 5, 'deiner': 1, 'Trauer,': 1, 'ohne': 2, 'Trudy,': 1, 'deine': 1, 'Frau,': 1, 'zu': 2, 'sein.': 3, 'Aber': 2, 'ja,': 1, 'denn': 1, 'eigentlich?': 1, 'Hast': 2, 'einmal': 2, 'nur': 2, 'erzhlt,': 1, 'was': 3, 'hundertfnf-': 1, 'undzwanzigmal': 1, 'geschehen': 1, 'ist,': 2, 'o.': 3, 'hundertfnfundzwanzigmal,': 1, 'usw.': 1, 'usf.?': 1, 'alle': 2, 'widerlegt,': 1, 'Sigi': 1, 'den': 3, 'Beweis': 1, 'erbracht,': 1, 'dass': 3, 'Trauerarbeit': 1, 'eine': 1, 'Irrefhrung': 1, 'Werner': 1, 'plausibel': 1, 'vorgemacht,': 1, 'sogenannter': 1, 'Umgang': 2, 'mit': 3, 'Verlusten': 1, 'Phrasen': 1, 'drischt,': 1, 'die': 13, 'Zeit': 2, 'der': 9, 'Lge': 1, 'berfhrt,': 1, 'Wunden': 1, 'restlos': 1, 'heilen': 1, 'soll.': 1, 'Sie': 1, 'heilt': 1, 'nichts,': 2, 'weder': 2, 'noch': 3, 'u.': 15, 'viel': 1, 'wenig.': 1, 'Ich': 7, 'habe': 2, 'Skripte': 1, 'durch': 2, 'muss': 1, 'zum': 4, 'Schluss': 1, 'Schluss,': 1, 'Schweigen': 1, 'grer': 1, 'ist': 7, 'als': 3, 'Sprechen.': 1, 'Auf': 2, 'Rckseite': 1, 'des': 2, 'Teppichs': 1, 'streichst': 1, 'nmlich': 1, 'Silben': 1, 'zweite': 1, 'aus': 1, 'dem': 2, 'durch,': 1, 'seiest': 1, 'statt': 1, 'Trudy': 1, 'um': 2, 'Selbstbetrug?': 1, 'Ist': 5, 'dies': 1, 'Kompromiss?': 1, 'Sprich:': 3, 'knnte': 1, 'leben,': 1, 'tu': 1, 'es': 3, 'jedoch': 1, 'nicht?': 2, 'Du': 1, 'sprichst': 2, 'Franz!': 1, 'leb': 1, 'Jetzt': 1, 'Tassilo': 1, 'Herbert!': 1, 'kann': 2, 'nicht': 13, 'leben': 2, 'genormter': 1, 'normal?': 1, 'Sprich': 2, 'doch': 2, 'Victor': 1, 'fast,': 1, 'fast': 1, 'Teddie!': 1, 'fr': 5, 'dich': 1, 'von': 4, 'andren': 1, 'Warten': 1, 'aus!': 1, 'nun': 1, 'uert': 1, 'sich': 2, 'Trauer?': 1, 'Als': 1, 'Angst': 1, 'vor': 1, 'jeglicher': 1, 'Vernderung.': 1, 'Wrd': 1, 'lachen,': 1, 'wenns': 1, 'betrfe.': 1, 'Wie': 4, 'ich': 5, 'Reisen': 1, 'sehe,': 1, 'dazu': 2, 'stehe?': 1, 'Geh': 1, 'mir': 1, 'weg': 1, 'Reisen!': 1, 'Berge,': 1, 'wandern?': 1, 'kme': 1, 'bis': 2, 'zur': 1, 'ersten': 1, 'Bank!': 1, 'wenn': 5, 'wirklich': 1, 'Berge': 1, 'reiste,': 1, 'wrd': 1, 'am': 1, 'liebsten': 1, 'geradeaus': 1, 'nach': 1, 'oben': 2, 'Gipfel,': 1, 'nhme': 1, 'selbst': 1, 'Umweg,': 1, 'auf': 1, 'ab': 1, 'zick': 1, 'zack.': 1, 'Wr': 1, 'blo': 1, 'tragikomisch,': 1, 'sagst,': 1, 'Verndrung': 1, 'kein': 1, 'Problem,': 1, 'will': 1, 'ich,': 1, 'sie': 1, 'eintritt,': 1, 'ihrer': 1, 'Nhe': 1, 'Monk,': 2, 'auch': 2, 'komisch': 1, 'Hr': 1, 'zu:': 1, 'Der': 2, 'einst': 1, 'Leninist': 1, 'FAZ': 1, 'Beschimpfte': 1, 'lies': 1, 'ihn': 1, 'mal!': 1, 'vertritt': 1, 'Meinung,': 1, 'Sahne': 1, 'sei': 1, 'frs': 2, 'Kochen,': 1, 'Schreiben': 2, 'Kitsch.': 1, 'sag': 1, 'nur:': 1, 'N,': 1, 'mein': 1, 'Kitsch': 1, 'Schmand.': 1, 'das': 2, 'sauer': 1, 'saukomisch,': 1, 'beinah': 1, 'tragikomisch?': 1, 'Lassen': 1, 'wirs': 1, 'so': 1, 'stehn.': 1, 'Heit': 1, 'Mitte': 1, 'gestorben': 1, 'sein': 1, 'Schreiben,': 1, 'Askese,': 1, 'drin': 1, 'Leichnams': 1, 'Lage': 1, 'imitiert': 1, 'wird?': 1, 'Alk': 1, 'Thromboseprophylaxe,': 1, 'Kaffee,': 1, 'Qualmen': 1, 'ein': 4, 'Schlot': 1, 'Genuss?': 1, 'Am': 1, 'Ende': 1, 'wird': 1, 'jeder': 1, 'eingeholt.': 1, 'da': 1, 'kennt': 1, 'rein': 1, 'gar': 1, 'heilig': 1, 'ihm': 1, 'nichts.': 1, 'Auch': 1, 'Snde': 1, 'schafft': 1, 'Erlsung.': 1, 'schlicht': 1, 'einfach': 1, 'Materialermdung,': 1, 'man': 3, 'Baum': 1, 'im': 1, 'Sptholzstadium,': 1, 'sind': 1, 'Jahresringe': 2, 'angezhlt?': 1, 'Trotzdem': 1, 'piesackt,': 1, 'piekst': 1, 'Gewissen': 1, 'einen': 3, 'an.': 1, 'Htte,': 1, 'htte,': 1, 'Fahrradkette,': 1, 'rette': 1, 'wer': 1, 'kann.': 1, 'Was': 1, 'tun?': 1, 'frag': 1, 'Freund,': 1, 'Kant,': 1, 'Marx': 1, 'Godard.': 1, 'irgendeine': 1, 'Fremdeinwirkung': 1, 'warten?': 1, 'Es': 1, 'groer': 1, 'Trost,': 1, 'Franz': 1, 'feuershalber': 1, 'Funken': 1, 'schlug.': 1, 'Mit': 1, 'wollt': 1, 'er': 1, 'einzig': 1, 'alleine': 1, 'seinen': 1, 'Leichnam': 2, 'luminieren.': 1, 'Nur': 1, 'eins': 1, 'bleibt': 1, 'vage:': 1, 'ob': 1, 'auen': 1, 'innen.': 1, 'Ihm': 1, 'schwebt': 1, 'Leuchtkraftkompetenz': 1, 'Kfern': 1, 'vor?': 1, 'sakrales': 1, 'Fenster?': 1, 'Sonne': 1, 'dringt': 1, 'Buntglas': 1, 'Symbolik': 1, 'Kircheninnenraum?': 1, 'begeht': 1, 'Leichnam?': 1, 'schreibt': 1, 'Zeug': 1, 'Schreiben?': 1, 'ihres': 1, 'Baums': 1, 'Geschichte?': 1, 'Was,': 1, 'einer': 2, 'dunkel': 1, 'schreibt,': 1, 'Recht-': 1, 'schreibfehler': 1, 'Dunkles': 1, 'obendrein': 1, 'verdunkeln': 1, 'Steigrung': 1, 'hchste': 1, 'Stufe': 1, 'Beleuchtung': 1, 'mehr': 1, 'dient?': 1, 'kontrastvermittelt': 1, 'rntgen,': 1, 'vom': 1, 'Dunkel': 1, 'herkommt?': 1}}, {'filename': 'sachliche-romanze-14375.json', 'gender': 'm', 'categories': ['Leben & Beziehungen', 'Frau', 'Mann', 'Ehe'], 'token_count': 113, 'word_frequency': {'Als': 1, 'sie': 5, 'einander': 1, 'acht': 1, 'Jahre': 1, 'kannten': 2, '(und': 1, 'man': 2, 'darf': 1, 'sagen:': 1, 'sich': 3, 'gut),': 1, 'kam': 1, 'ihre': 1, 'Liebe': 1, 'pltzlich': 1, 'abhanden.': 1, 'Wie': 1, 'andern': 1, 'Leuten': 1, 'ein': 2, 'Stock': 1, 'oder': 1, 'Hut.': 1, 'Sie': 3, 'waren': 1, 'traurig,': 1, 'betrugen': 1, 'heiter,': 1, 'versuchten': 1, 'Ksse,': 1, 'als': 1, 'ob': 1, 'nichts': 1, 'sei,': 1, 'und': 6, 'sahen': 1, 'an': 1, 'wuten': 1, 'nicht': 2, 'weiter.': 1, 'Da': 1, 'weinte': 1, 'schlielich.': 1, 'Und': 1, 'er': 1, 'stand': 1, 'dabei.': 1, 'Vom': 1, 'Fenster': 1, 'aus': 1, 'konnte': 1, 'Schiffen': 1, 'winken.': 1, 'Er': 1, 'sagte,': 1, 'es': 2, 'wre': 1, 'schon': 1, 'Viertel': 1, 'nach': 1, 'Vier': 1, 'Zeit,': 1, 'irgendwo': 1, 'Kaffee': 1, 'zu': 1, 'trinken.': 1, 'Nebenan': 1, 'bte': 1, 'Mensch': 1, 'Klavier.': 1, 'gingen': 1, 'ins': 1, 'kleinste': 1, 'Cafe': 1, 'am': 1, 'Ort': 1, 'rhrten': 1, 'in': 1, 'ihren': 1, 'Tassen.': 1, 'Am': 1, 'Abend': 1, 'saen': 2, 'immer': 1, 'noch': 1, 'dort.': 1, 'allein,': 1, 'sprachen': 1, 'kein': 1, 'Wort': 1, 'konnten': 1, 'einfach': 1, 'fassen.': 1}}]\n"
     ]
    }
   ],
   "source": [
    "# Funktion um den Korpus nach den Kategorien zu durchsuchen und die entsprechenden Dateien auszugeben\n",
    "def get_file_info(category, directory):\n",
    "    file_info = []\n",
    "\n",
    "    # Gehe durch alle Dateien im Verzeichnis\n",
    "    for filename in os.listdir(directory):\n",
    "        # Überprüfe nur .json Dateien\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            # Lese die Datei als json\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                # Überprüfe, ob die Kategorie in der Liste 'categories' vorhanden ist\n",
    "                if category in data.get('categories', []):\n",
    "                    # Wenn ja, extrahiere zusätzliche Informationen\n",
    "                    info = {\n",
    "                        'filename': filename,\n",
    "                        'gender': data.get('gender'),\n",
    "                        'categories': data.get('categories')\n",
    "                    }\n",
    "                    \n",
    "                    # Tokenisiere den Text des Gedichts und berechne die Anzahl der Token und die Wortfrequenz\n",
    "                    poem_text = \" \".join([line['text'] for line in data.get('poem', {}).values()])\n",
    "                    tokens = poem_text.split()\n",
    "                    info['token_count'] = len(tokens)\n",
    "                    info['word_frequency'] = dict(Counter(tokens))\n",
    "                    \n",
    "                    file_info.append(info)\n",
    "\n",
    "    return file_info\n",
    "\n",
    "# Teste die Funktion\n",
    "print(get_file_info('Ehe', r'C:\\Users\\vinze\\Desktop\\Uni\\DH\\Forschun gsmethoden\\corpus_finished'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>gender</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line.1</th>\n",
       "      <td>125 Episoden</td>\n",
       "      <td>125-episoden-imonki-16200</td>\n",
       "      <td>m</td>\n",
       "      <td>Alexandru Bulucz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.2</th>\n",
       "      <td>Monk</td>\n",
       "      <td>125-episoden-imonki-16200</td>\n",
       "      <td>m</td>\n",
       "      <td>Alexandru Bulucz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.3</th>\n",
       "      <td>. In Worten: einhundertfnfundzwanzig Episoden,...</td>\n",
       "      <td>125-episoden-imonki-16200</td>\n",
       "      <td>m</td>\n",
       "      <td>Alexandru Bulucz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.4</th>\n",
       "      <td>Stell dir vor, wie oft du mich begleitet hast ...</td>\n",
       "      <td>125-episoden-imonki-16200</td>\n",
       "      <td>m</td>\n",
       "      <td>Alexandru Bulucz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.5</th>\n",
       "      <td>zu sein. Aber ja, wie oft denn eigentlich? Has...</td>\n",
       "      <td>125-episoden-imonki-16200</td>\n",
       "      <td>m</td>\n",
       "      <td>Alexandru Bulucz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.4</th>\n",
       "      <td>die Liebe, das Knie und der Rcken.</td>\n",
       "      <td>zwischenbilanz-12762</td>\n",
       "      <td>m</td>\n",
       "      <td>F. W. Bernstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.5</th>\n",
       "      <td>Interviews, Fupflege, Reimweh und Ruhm</td>\n",
       "      <td>zwischenbilanz-12762</td>\n",
       "      <td>m</td>\n",
       "      <td>F. W. Bernstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.6</th>\n",
       "      <td>Beamtenschaft, Zahnersatz, Brillen</td>\n",
       "      <td>zwischenbilanz-12762</td>\n",
       "      <td>m</td>\n",
       "      <td>F. W. Bernstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.7</th>\n",
       "      <td>und wenn der Humor mich allzusehr plagt</td>\n",
       "      <td>zwischenbilanz-12762</td>\n",
       "      <td>m</td>\n",
       "      <td>F. W. Bernstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.8</th>\n",
       "      <td>nehm ich scherzstillende Mittel</td>\n",
       "      <td>zwischenbilanz-12762</td>\n",
       "      <td>m</td>\n",
       "      <td>F. W. Bernstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5719 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "line.1                                       125 Episoden   \n",
       "line.2                                               Monk   \n",
       "line.3  . In Worten: einhundertfnfundzwanzig Episoden,...   \n",
       "line.4  Stell dir vor, wie oft du mich begleitet hast ...   \n",
       "line.5  zu sein. Aber ja, wie oft denn eigentlich? Has...   \n",
       "...                                                   ...   \n",
       "line.4                 die Liebe, das Knie und der Rcken.   \n",
       "line.5             Interviews, Fupflege, Reimweh und Ruhm   \n",
       "line.6                 Beamtenschaft, Zahnersatz, Brillen   \n",
       "line.7            und wenn der Humor mich allzusehr plagt   \n",
       "line.8                    nehm ich scherzstillende Mittel   \n",
       "\n",
       "                            title gender            author  \n",
       "line.1  125-episoden-imonki-16200      m  Alexandru Bulucz  \n",
       "line.2  125-episoden-imonki-16200      m  Alexandru Bulucz  \n",
       "line.3  125-episoden-imonki-16200      m  Alexandru Bulucz  \n",
       "line.4  125-episoden-imonki-16200      m  Alexandru Bulucz  \n",
       "line.5  125-episoden-imonki-16200      m  Alexandru Bulucz  \n",
       "...                           ...    ...               ...  \n",
       "line.4       zwischenbilanz-12762      m   F. W. Bernstein  \n",
       "line.5       zwischenbilanz-12762      m   F. W. Bernstein  \n",
       "line.6       zwischenbilanz-12762      m   F. W. Bernstein  \n",
       "line.7       zwischenbilanz-12762      m   F. W. Bernstein  \n",
       "line.8       zwischenbilanz-12762      m   F. W. Bernstein  \n",
       "\n",
       "[5719 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
