{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "# Specify the URL for scraping\n",
    "url = 'https://www.lyrikline.org/de/gedichte?query=&onlynewoff=&lang[]=de&translatorname=999999&category[]=66'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_poem_links(url, site:int):\n",
    "    \n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"-headless\")\n",
    "\n",
    "    # Set up Firefox service\n",
    "    webdriver_service = Service('geckodriver.exe')\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox(service=webdriver_service, options=firefox_options)\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the dynamic content to load (you may need to adjust the waiting time based on the page)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    \n",
    "    # Get the page source after the content is loaded\n",
    "    for i in range(site):\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//a[contains(text(), \"nächste\")]')\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "        except:\n",
    "            break\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Process the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find and extract the desired elements using BeautifulSoup\n",
    "    # Example: Get the titles of the poems\n",
    "    poem_links = []\n",
    "    link_elements = soup.find_all('a', class_='row')\n",
    "    \n",
    "    for link in link_elements:\n",
    "        href = link.get('href')\n",
    "        poem_links.append(href)\n",
    "    \n",
    "    return poem_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_poem(url, title):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    poem_div = soup.find('div', class_='gedicht-originaltext clearfix')\n",
    "    poem_lines = [line.strip() for line in poem_div.stripped_strings]\n",
    "    \n",
    "    author_h1 = soup.find('h1', id='gedicht-autor')\n",
    "    author_name = author_h1.find('a').text.strip() if author_h1 else ''\n",
    "    \n",
    "    poem_data = {\n",
    "        'title': title,\n",
    "        'gender': '',\n",
    "        'author': author_name,\n",
    "        'poem': {}\n",
    "    }\n",
    "    \n",
    "    for idx, line in enumerate(poem_lines, start=1):\n",
    "        poem_data['poem'][f'line.{idx}'] = {'text': line.strip()}\n",
    "    \n",
    "    return poem_data\n",
    "\n",
    "\n",
    "def save_to_json(poem_data, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        json.dump(poem_data, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping poems:  24%|██▍       | 29/120 [00:41<03:19,  2.20s/poem]"
     ]
    }
   ],
   "source": [
    "# Scrape the poem links\n",
    "url = 'https://www.lyrikline.org/de/gedichte?query=&onlynewoff=&lang[]=de&translatorname=999999&category[]=66'\n",
    "poem_links = []\n",
    "site_number = 6\n",
    "for i in range(site_number):\n",
    "    poem_links += scrape_poem_links(url, i)\n",
    "\n",
    "# Create a \"corpus\" folder if it doesn't exist\n",
    "corpus_folder = 'corpus_selenium'\n",
    "os.makedirs(corpus_folder, exist_ok=True)\n",
    "\n",
    "# Scrape and save the poems\n",
    "for link in tqdm(poem_links, desc='Scraping poems', unit='poem'):\n",
    "    title = link.split('/')[-1]\n",
    "    poem_url = f'https://www.lyrikline.org{link}'\n",
    "    poem_data = scrape_poem(poem_url, title)\n",
    "    file_name = os.path.join(corpus_folder, f'{title}.json')\n",
    "    save_to_json(poem_data, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
