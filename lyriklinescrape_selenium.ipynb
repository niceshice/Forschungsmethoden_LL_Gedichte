{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_poem_links(url, site:int):\n",
    "    \n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"-headless\")\n",
    "\n",
    "    # Set up Firefox service\n",
    "    webdriver_service = Service('geckodriver.exe')\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the dynamic content to load (you may need to adjust the waiting time based on the page)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    \n",
    "    # Get the page source after the content is loaded\n",
    "    for i in range(site):\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//a//span[contains(text(), \"nächste\")]')\n",
    "            print(next_button)\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "        except:\n",
    "            break\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Process the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find and extract the desired elements using BeautifulSoup\n",
    "    # Example: Get the titles of the poems\n",
    "    poem_links = []\n",
    "    link_elements = soup.find_all('a', class_='row')\n",
    "    \n",
    "    for link in link_elements:\n",
    "        href = link.get('href')\n",
    "        poem_links.append(href)\n",
    "    \n",
    "    return poem_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_poem(url, title, gender):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    poem_div = soup.find('div', class_='gedicht-originaltext clearfix')\n",
    "    poem_lines = [line.strip() for line in poem_div.stripped_strings]\n",
    "    \n",
    "    author_h1 = soup.find('h1', id='gedicht-autor')\n",
    "    author_name = author_h1.find('a').text.strip() if author_h1 else ''\n",
    "\n",
    "    categories_table = soup.find('table', class_='kat')\n",
    "    categories_links = categories_table.find_all('a')\n",
    "    categories = [link.text.strip() for link in categories_links]\n",
    "    \n",
    "    poem_data = {\n",
    "        'title': title,\n",
    "        'categories': categories,\n",
    "        'gender': gender,\n",
    "        'author': author_name,\n",
    "        'poem': {}\n",
    "    }\n",
    "    \n",
    "    for idx, line in enumerate(poem_lines, start=1):\n",
    "\n",
    "        filtered_line = re.sub(r'[^\\x00-\\x7FäöüÄÖÜß]+', '', line)\n",
    "        filtered_line = filtered_line.strip()\n",
    "\n",
    "        poem_data['poem'][f'line.{idx}'] = {'text': filtered_line}\n",
    "    \n",
    "    return poem_data\n",
    "\n",
    "\n",
    "def save_to_json(poem_data, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        json.dump(poem_data, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"d9794976-0277-4c4d-a260-98b6acbbd0c0\", element=\"af46de62-682e-4cbc-908e-ab78c3b0603a\")>\n",
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"d1dbedb9-cfce-416f-9718-6d6bc2da9411\", element=\"3e329b9d-1f42-40f2-927c-5e39ee79ee23\")>\n",
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"d1dbedb9-cfce-416f-9718-6d6bc2da9411\", element=\"7ab545ed-b709-462d-a4cd-28afae35d20a\")>\n"
     ]
    }
   ],
   "source": [
    "# Scrape the poem links\n",
    "gender = 'w'\n",
    "category = 66\n",
    "sites = 4\n",
    "url = f'https://www.lyrikline.org/de/gedichte?query=&onlynewoff=&lang[]=de&translatorname=999999&category[]={category}&geschlecht[]={gender}'\n",
    "poem_links = scrape_poem_links(url, sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"corpus\" folder if it doesn't exist\n",
    "corpus_folder = f'corpus_finished'\n",
    "os.makedirs(corpus_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping poems:   0%|          | 0/53 [00:00<?, ?poem/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping poems: 100%|██████████| 53/53 [01:33<00:00,  1.77s/poem]\n"
     ]
    }
   ],
   "source": [
    "# Scrape and save the poems\n",
    "for link in tqdm(poem_links, desc='Scraping poems', unit='poem'):\n",
    "    title = link.split('/')[-1]\n",
    "    poem_url = f'https://www.lyrikline.org{link}'\n",
    "    poem_data = scrape_poem(poem_url, title)\n",
    "    file_name = os.path.join(corpus_folder, f'{title}.json')\n",
    "    save_to_json(poem_data, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
